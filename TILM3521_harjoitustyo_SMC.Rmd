---
title: "SMC-menetelmät"
subtitle: "Laskennallinen tilastotiede - Harjoitustyö"
author: "Lasse Rintakumpu"
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
   - \usepackage{color}
urlcolor: blue   
linkcolor: blue
citecolor: blue
output:
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
citation_package: natbib
lang: fi
---

\setlength\parindent{24pt}
\setlength\parskip{3pt}

```{r setup, include=FALSE, cache=FALSE}
#Knitr options
knitr::opts_chunk$set(echo = FALSE, fig.width=3, fig.height=2.8, fig.show='hold', fig.align='center', warning = FALSE, cache = TRUE, cache.path = 'output/cache/', fig.path = 'output/figures/')

# Used libraries
library(knitr) # For creating PDF
library(pander)
```

# Johdanto

SMC-menetelmät (Sequential Monte Carlo -mentelmät, tunnetaan myös nimellä hiukkassuotimet) ovat joukko 90-luvulta eteenpäin kehitettyjä algoritmeja ja tilastollisia menetelmiä, joiden avulla voidaan approksimoida ns. suodinongelmaa. Tämän tutkielman tavoitteena on esittää pääpiirteittään SMC-menetelmien teoria sekä joitakin menetelmäperheeseen kuuluvia algoritmeja. Tutkielman esitykset seuraavat erityisesti LÄHTEET. SMC-menetelmille on lukuisia sovellutuksia fysiikasta robotiikkaan. Tämän tutkielman lopussa tarkastellaan hiukkassuotimen käyttöä paikannussovelluksessa.

## Suodinongelma

Signaalinkäsittelyssä ja tilastotieteessä suodinongelmaksi kutsutaan XXX Hiukkassuotimen tavoitteena on estimoida "piilossa olevien" tilojen posteriorijakauma havaintojen perusteella. Lisäksi tiedetään miten havaitut muuttujat kytkeytyvät "piilossa oleviin" muuttujiin sekä osaamme sanoa jotain tilamuuttujien todennäköisyyksistä. Signaalinkäsittelyssä tätä kutsutaan suodinongelmaksi. Ongelmaa havainnollistaa kaavio (1).

n the theory of stochastic processes, the filtering problem is a mathematical model for a number of state estimation problems in signal processing and related fields. The general idea is to establish a "best estimate" for the true value of some system from an incomplete, potentially noisy set of observations on that system. Hiukkassuotimet (*particle filters*, tunnetaan myös nimellä sekventiaaliset Monte Carlo -menetelmät, *sequential Monte Carlo*, SMC) ovat joukko 90-luvulta eteenpäin kehitettyjä menetelmiä, joiden avulla voidaan approksimoida epälineaarista Bayes-rekursiota / suodinongelmaa. 

Menetelmissä käytetään otoksia (kutsutaan myös partikkeleiksi) esittämään jonkin stokastisen prosessin posteriorijakaumaa, kun vain osa havainnoista tunnetaan ja/tai havaintoihin liittyy kohinaa.

\begin{align}
&X_1 \hspace{0.3cm} \rightarrow \hspace{0.3cm} X_2 \hspace{0.3cm} \rightarrow  \hspace{0.3cm} X_3 \hspace{0.3cm} \rightarrow \hspace{0.3cm}\ldots \hspace{0.3cm} \text{piilossa olevat tilat} \\
&\downarrow \hspace{1.4cm} \downarrow \hspace{1.41cm} \downarrow \hspace{0.3cm} \\
&Y_1 \hspace{0.3cm} \rightarrow \hspace{0.3cm} Y_2 \hspace{0.3cm} \rightarrow  \hspace{0.3cm} Y_3 \hspace{0.3cm} \rightarrow \hspace{0.3cm}\ldots \hspace{0.3cm} \text{havainnot}.
\end{align}

Hiukkassuodin estimoi *sekventiaalisesti* tilojen $X_k$ arvot minä hyvänsä ajan hetkellä $k$, kun ainoastaan prosessi $Y_1, \ldots, Y_k$ tunnetaan. Estimaatit saadaan posteriorijakaumasta $p(x_k | y_1,y_2,\ldots, y_k)$, jolle siis muodostetaan Bayesilaisittain approksimaatio havaintojen pohjalta.

Merkitään piilossa olevan prosessin tilaa ajanhetkellä $k$ $x_k$ ja havaittua prosessia $y_k$. Aika-avaruus on diskreetti. Hiukkassuodinta varten määritellään prosesseille mallit

$$
\begin{aligned}
&x_{k+1} \sim p(x_{k+1}|x_k)\\
&y_{k} \sim p(y_k|x_k),
\end{aligned}
$$

joiden pohjalta halutaan laskea posteriorijakauma $p(x_k|y_{1:k})$. Nämä vastaavat aiemmin määriteltyä ehtoa "tiedetään miten havaitut muuttujat kytkeytyvät "piilossa oleviin" muuttujiin ($y_k$) sekä osaamme sanoa jotain tilamuuttujien todennäköisyyksistä ($x_{k+1}$)".

## Historiaa

Suodinongelma on ... ratkaisuja linearisoinnista. Ensimmäisen Bayesilaisen/MC-ratkaisun esittivät ... . Ero tähän esitykseen. Alla käytetään modernia esitystä, jonka suurin ero aiempiin on ... .

# Bayesilainen suodin

Bayesilainen suodin on XXX. Tässä esitety versio on XXX. Bayesilainen ratkaisu posteriorijakaumalle saadaan seuraavalla rekursiolla (käydään läpi jokaiselle ajanhetkelle $k=1,\ldots,t$). Lasketaan ensin

\begin{align}
p(x_k|y_{1:k}) = \frac{p(y_k|x_k)p(x_k|y_{1:k-1})}{p(y_k|y_{1:k-1})},
\end{align}

joka saadaan suoraan Bayesin kaavasta $P(A|B)=P(B|A)P(A)/P(B)$. Normalisointivakio lasketaan integraalina 

\begin{align}
p(y_k|y_{1:k-1})=\int_{\mathbb{R}^{n_x}}p(y_k|x_k)p(x_k|y_{1:k-1})\mathop{dx_k},
\end{align}

joka saadaan kokonaistodennäköisyyskaavasta $P(A)=\mathbb{E}[P(A|X)]=\int_{-\infty}^{\infty}P(A|X=x)f_X(x)\mathop{dx}$. Merkintä ${R}^{n_x}$ vastaa tässä piilossa olevien muuttujien dimensiota $n$.

Lopuksi lasketaan päivitysaskel ajalle, joka saadaan edelleen kokonaistodennäköisyydellä

\begin{align}
p(x_{k+1}|y_{1:k})=\int_{\mathbb{R}^{n_x}}p(x_{k+1}|x_k)p(x_k|y_{1:k})\mathop{dx_k}.
\end{align}

Rekursion avulla voidaan siis laskea $p(x_k|y_{1:k})$ käymällä rekursio läpi $k$ kertaa.

# Hiukassuodin-algoritmi

Tässä luvussa esitetään algoritmi, joka toteuttaa yllä esitetyn Bayesilaisen suotimen. Luku koostuu XXX algoritmi XX ennen ehdotusjakauman valinta (optimaalinen) lopuksi käsitellään algoritmin marginaalijakaumaa ja aikakompleksisuutta. Esitetään myös ONLOGN-versio algoritmista.

## Ehdotusjakauman valinta

Ennen algoritmin suorittamista valitaan ehdotusjakauma $q(x_{k+1}|x_{1:k},y_{k+1})$, uudelleenotantamenetelmä sekä partikkelien määrä $N$. Ehdotusjakauman valintaa ei käsitellä tässä, mutta valinta voidaan tehdä optimaalisesti. Yksinkertaisin valinta on $q(x_{k+1}|x_{1:k},y_{k+1})=p(x_{k+1}|x_{1:k})$.

## Algoritmi

Alla käytetään notaatiota $x_k^i$, joka tarkoittaa, että tila $x_k$ käy ajanhetkellä $k$ gridin pisteessä $x^i$. Notaatiota tarvitaan, koska hiukkassuotimessa läpikäytävä gridi muuttuu ajan funktiona.

**Alustus:** Generoidaan $x_1^i\sim p_{x_0}$ missä $i=1,\ldots,N$ ja jokainen partikkeli saa saman painon $w_{1|0}^i=1/N$.

Jokaiselle ajanhetkelle $k=1,2,\ldots,t$ toistetaan seuraava laskenta.

**Vaihe 1:** Päivitetään havainnot. Jokaiselle partikkelille $i=1,2,\ldots,N$ lasketaan painot

$$
w_{k|k}^i=\frac{1}{c_k}w_{k|{k-1}}^ip(y_k|x_k^i),
$$

missä normalisointipaino on

$$
c_k=\sum_{i=1}^{N}w_{k|{k-1}}^ip(y_k|x_k^i).
$$

**Vaihe 2:** Estimoidaan $p$. Lasketaan tiheydelle approksimaatio

$$
\hat{p}(x_{1:k}|y_{1:k})=\sum_{i=1}^{N}w_{k|k}^i \delta(x_{1:k}-x_{1:k}^i),
$$

missä $\delta(x)$ on Diracin deltafunktio.

**Vaihe 3:** Valinnainen uudelleenotanta. Otetaan uudet $N$ otosta palauttaen joukosta $\{x_{1:k}^i\}_{i=1}^N$, missä otoksen $i$ todennäköisyys on $w^i_{k|k}$.

Uudelleenotantaa tarvitaan, koska ilman sitä painot alkavat keskittyä muutaman ajanhetken jälkeen tietyille partikkeleille. Uudelleenotantaa ei kuitenkaan kannata aloittaa liian aikaisin, koska se lisää satunnaisotannan epävarmuutta. 

**Vaihe 4:** Aikapäivitys, jos $k < t$. Luodaan ennusteet partikkeleille ehdotusjakaumasta

$$
x_{k+1}^i\sim q(x_{k+1}|x_k^i,y_{k+1})
$$

ja päivitetään myös partikkelien painot tärkeytysotannalla sen mukaan kuinka todennäköisiä partikkelien ennusteet ovat

$$
w_{k+1|k}^i=w_{k|k}^i\frac{p(x_{k+1}^i|x_k^i)}{q(x_{k+1}^i|x_k^i,y_{k+1})}.
$$

Palataan takaisin **vaiheeseen 1**. Jatketaan kunnes $k=t$. Kun $N \rightarrow \infty$ algoritmille pätee $\hat{p}(x_{1:k}|y_{1:k}) \xrightarrow{a.s.} p(x_{1:k}|y_{1:k})$.

## Marginaalijakauma

Edellä kuvattu algoritmi tuottaa approksimaation koko prosessin posteriorijakaumalle $p(x_{1:k}|y_{1:k})$. Jos halutaan tietää ainoastaan posteriorijakauman $p(x_k|y_{1:k})$ estimaatti, voidaan käyttää ainoastaan viimeisestä tilasta $x_k^i$ laskettua estimaattia 

$$
\hat{p}(x_{k}|y_{1:k})=\sum_{i=1}^{N}w_{k|k}^i \delta(x_{k}-x_{k}^i).
$$

Toinen vaihtoehto on käyttää laskennassa tärkeytyspainoa

$$
w_{k+1|k}^i=\frac{\sum_{j=1}^{N}w_{k|k}^jp(x_{k+1}^i|x_k^j)}{q(x_{k+1}^i|x_k^i,y_{k+1})}
$$

yllä esitetyn sijaan. Tällöin jokaisessa aikapäivitysaskeleessa lasketaan painot kaikkien mahdollisten tila-aika-avaruuspolkujen yli. Samoin kuin uudelleenotanta tämä pienentää painojen varianssia.

## Aikakompleksisuus

Menetelmä kuitenkin lisää algoritmin aikakompleksisuutta $\mathcal{O}(N)\rightarrow\mathcal{O}(N^2)$, joten isoilla arvoilla $N$ pitää käyttää jotakin toista versiota algoritmista. Esimerkiksi $\mathcal{O}(N\text{log}(N))$ versio tästä marginaalihiukkassuotimesta on olemassa.

# Paikannusesimerkki

Esimerkissä analysoidaan ja vertaillaan myös eri versioiden suorituskykyä.

# Lopuksi

# Lähteet    

- Dahlin & Schön (2019): **Getting Started with Particle Metropolis-Hastings
for Inference in Nonlinear Dynamical Models**. [https://arxiv.org/pdf/1511.01707.pdf](https://arxiv.org/pdf/1511.01707.pdf).
- Gordon, Salmond & Smith (1993): **Novel approach to nonlinear/non-Gaussian Bayesian state estimation**. [http://www.irisa.fr/aspi/legland/ref/gordon93a.pdf](http://www.irisa.fr/aspi/legland/ref/gordon93a.pdf).
- Gustafsson (2010): **Particle Filter Theory and
Practice with Positioning
Applications**. [https://ieeexplore.ieee.org/document/5546308](https://ieeexplore.ieee.org/document/5546308).
- Särkkä (2013): **Bayesian Filtering and Smoothing.** Cambridge University Press.
[https://users.aalto.fi/~ssarkka/pub/cup_book_online_20131111.pdf](https://users.aalto.fi/~ssarkka/pub/cup_book_online_20131111.pdf).
